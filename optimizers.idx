SGD	optimizers.html#SGD	optimizers: SGD	
newSGD	optimizers.html#newSGD,varargs[Variable[Tensor[T]]],T	optimizers: newSGD[T](params: varargs[Variable[Tensor[T]]]; learning_rate: T): SGD[Tensor[T]]	
update	optimizers.html#update,SGD	optimizers: update(self: SGD)	
optimizer	optimizers.html#optimizer,M,typedesc[SGD],T	optimizers: optimizer[M, T](model: M; OptimizerKind: typedesc[SGD]; learning_rate: T): SGD[\n    Tensor[T]]	
optimizerSGD	optimizers.html#optimizerSGD,M,T	optimizers: optimizerSGD[M, T](model: M; learning_rate: T): SGD[Tensor[T]]	
SGDMomentum	optimizers.html#SGDMomentum	optimizers: SGDMomentum	
update	optimizers.html#update,SGDMomentum	optimizers: update(self: var SGDMomentum)	
optimizer	optimizers.html#optimizer,M,typedesc[SGDMomentum],T,T,T	optimizers: optimizer[M, T](model: M; OptimizerKind: typedesc[SGDMomentum];\n                learning_rate: T; momentum: T = T(0.0); decay: T = T(0.0);\n                nesterov = false): SGDMomentum[Tensor[T]]	
optimizerSGDMomentum	optimizers.html#optimizerSGDMomentum,M,T,typeof(T(0.0)),typeof(T(0.0))	optimizers: optimizerSGDMomentum[M, T](model: M; learning_rate: T; momentum = T(0.0);\n                           decay = T(0.0); nesterov = false): SGDMomentum[\n    Tensor[T]]	
Adam	optimizers.html#Adam	optimizers: Adam	
update	optimizers.html#update,Adam	optimizers: update(self: var Adam)	
optimizer	optimizers.html#optimizer,M,typedesc[Adam],T,T,T,T	optimizers: optimizer[M, T](model: M; OptimizerKind: typedesc[Adam];\n                learning_rate: T = T(0.001); beta1: T = T(0.9);\n                beta2: T = T(0.999); eps: T = T(1e-8)): Adam[Tensor[T]]	
optimizerAdam	optimizers.html#optimizerAdam,M,T,T,T,T	optimizers: optimizerAdam[M, T](model: M; learning_rate: T; beta1: T = T(0.9);\n                    beta2: T = T(0.999); eps: T = T(1e-8)): Adam[Tensor[T]]	
Optimizer	optimizers.html#Optimizer	optimizers: Optimizer	
zeroGrads	optimizers.html#zeroGrads,Optimizer	optimizers: zeroGrads(o: Optimizer)	
